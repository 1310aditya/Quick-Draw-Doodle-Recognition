{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% import\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import ast\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw \n",
    "from tqdm import tqdm\n",
    "from dask import bag\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countrycode</th>\n",
       "      <th>drawing</th>\n",
       "      <th>key_id</th>\n",
       "      <th>recognized</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[46, 21, 9, 0, 0, 8, 19, 46, 92, 127, 135, 1...</td>\n",
       "      <td>5696968749744128</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-29 02:40:55.895800</td>\n",
       "      <td>pear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[75, 74, 56, 38, 33, 34, 30, 18, 2, 0, 7, 16...</td>\n",
       "      <td>4914459074101248</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-26 20:50:44.270270</td>\n",
       "      <td>pear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SG</td>\n",
       "      <td>[[[0, 29, 47, 51, 72, 108, 118, 120, 109, 93, ...</td>\n",
       "      <td>5564384250167296</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-27 07:19:56.813180</td>\n",
       "      <td>golf club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[64, 46, 11, 3, 0, 0, 7, 33, 70, 75, 71, 72,...</td>\n",
       "      <td>6515822719664128</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-27 16:28:31.066620</td>\n",
       "      <td>golf club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JP</td>\n",
       "      <td>[[[125, 149, 174], [103, 63, 34]], [[131, 174]...</td>\n",
       "      <td>5235884959989760</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-13 03:15:45.652170</td>\n",
       "      <td>violin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[43, 38, 21, 11, 8, 12, 33, 39, 37, 17, 23, ...</td>\n",
       "      <td>6379764493320192</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-01 15:01:12.859650</td>\n",
       "      <td>violin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[122, 132, 140, 151, 155, 151, 139, 128, 121...</td>\n",
       "      <td>5005830493569024</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-02 17:07:16.356190</td>\n",
       "      <td>flashlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[89, 84, 84, 93, 97, 98, 95], [1, 22, 47, 51...</td>\n",
       "      <td>5955411502956544</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-08 16:42:14.551860</td>\n",
       "      <td>flashlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>[[[0, 11, 30, 39, 139, 219, 225, 234, 237, 242...</td>\n",
       "      <td>6534791572750336</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-08 20:50:13.751640</td>\n",
       "      <td>swing set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RU</td>\n",
       "      <td>[[[26, 26, 3, 0], [6, 70, 131, 190]], [[26, 32...</td>\n",
       "      <td>4527001002049536</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-31 13:01:55.805850</td>\n",
       "      <td>swing set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CA</td>\n",
       "      <td>[[[22, 45, 56, 59, 53, 36, 25, 23, 29], [185, ...</td>\n",
       "      <td>5722353180868608</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-01-24 01:40:15.037620</td>\n",
       "      <td>lighthouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CZ</td>\n",
       "      <td>[[[33, 30, 42], [65, 193, 255]], [[92, 90, 98]...</td>\n",
       "      <td>5180039031160832</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-03 16:15:03.971070</td>\n",
       "      <td>lighthouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   countrycode                                            drawing  \\\n",
       "0           US  [[[46, 21, 9, 0, 0, 8, 19, 46, 92, 127, 135, 1...   \n",
       "1           US  [[[75, 74, 56, 38, 33, 34, 30, 18, 2, 0, 7, 16...   \n",
       "2           SG  [[[0, 29, 47, 51, 72, 108, 118, 120, 109, 93, ...   \n",
       "3           US  [[[64, 46, 11, 3, 0, 0, 7, 33, 70, 75, 71, 72,...   \n",
       "4           JP  [[[125, 149, 174], [103, 63, 34]], [[131, 174]...   \n",
       "5           US  [[[43, 38, 21, 11, 8, 12, 33, 39, 37, 17, 23, ...   \n",
       "6           US  [[[122, 132, 140, 151, 155, 151, 139, 128, 121...   \n",
       "7           US  [[[89, 84, 84, 93, 97, 98, 95], [1, 22, 47, 51...   \n",
       "8           US  [[[0, 11, 30, 39, 139, 219, 225, 234, 237, 242...   \n",
       "9           RU  [[[26, 26, 3, 0], [6, 70, 131, 190]], [[26, 32...   \n",
       "10          CA  [[[22, 45, 56, 59, 53, 36, 25, 23, 29], [185, ...   \n",
       "11          CZ  [[[33, 30, 42], [65, 193, 255]], [[92, 90, 98]...   \n",
       "\n",
       "              key_id recognized                   timestamp        word  \n",
       "0   5696968749744128       True  2017-01-29 02:40:55.895800        pear  \n",
       "1   4914459074101248       True  2017-03-26 20:50:44.270270        pear  \n",
       "2   5564384250167296       True  2017-01-27 07:19:56.813180   golf club  \n",
       "3   6515822719664128       True  2017-01-27 16:28:31.066620   golf club  \n",
       "4   5235884959989760       True  2017-01-13 03:15:45.652170      violin  \n",
       "5   6379764493320192       True  2017-03-01 15:01:12.859650      violin  \n",
       "6   5005830493569024       True  2017-03-02 17:07:16.356190  flashlight  \n",
       "7   5955411502956544       True  2017-01-08 16:42:14.551860  flashlight  \n",
       "8   6534791572750336       True  2017-03-08 20:50:13.751640   swing set  \n",
       "9   4527001002049536       True  2017-01-31 13:01:55.805850   swing set  \n",
       "10  5722353180868608       True  2017-01-24 01:40:15.037620  lighthouse  \n",
       "11  5180039031160832       True  2017-03-03 16:15:03.971070  lighthouse  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = glob('train_simplified/*.csv')\n",
    "cnames = ['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word']\n",
    "drawlist = []\n",
    "for f in fnames[0:6]:\n",
    "    first = pd.read_csv(f, nrows=10) # make sure we get a recognized drawing\n",
    "    first = first[first.recognized==True].head(2)\n",
    "    drawlist.append(first)\n",
    "draw_df = pd.DataFrame(np.concatenate(drawlist), columns=cnames)\n",
    "draw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% set label dictionary and params\n",
    "classfiles = os.listdir('train_simplified/')\n",
    "numstonames = {i: v[:-4].replace(\" \", \"_\") for i, v in enumerate(classfiles)} #adds underscores\n",
    "\n",
    "num_classes = 30    #340 max \n",
    "imheight, imwidth = 225, 225  \n",
    "ims_per_class = 2000  #max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# faster conversion function\n",
    "def draw_it(strokes):\n",
    "    image = Image.new(\"P\", (256,256), color=255)\n",
    "    image_draw = ImageDraw.Draw(image)\n",
    "    for stroke in ast.literal_eval(strokes):\n",
    "        for i in range(len(stroke[0])-1):\n",
    "            image_draw.line([stroke[0][i], \n",
    "                             stroke[1][i],\n",
    "                             stroke[0][i+1], \n",
    "                             stroke[1][i+1]],\n",
    "                            fill=0, width=5)\n",
    "    image = image.resize((imheight, imwidth))\n",
    "    return np.array(image)/255.\n",
    "\n",
    "#%% get train arrays\n",
    "train_grand = []\n",
    "class_paths = glob('train_simplified/*.csv')\n",
    "#print(class_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled 30 classes.\n",
      "train_simplified/hat.csv\n",
      "train_simplified/penguin.csv\n",
      "train_simplified/barn.csv\n",
      "train_simplified/sword.csv\n",
      "train_simplified/grass.csv\n",
      "train_simplified/tiger.csv\n",
      "train_simplified/laptop.csv\n",
      "train_simplified/hexagon.csv\n",
      "train_simplified/raccoon.csv\n",
      "train_simplified/light bulb.csv\n",
      "train_simplified/mailbox.csv\n",
      "train_simplified/submarine.csv\n",
      "train_simplified/dishwasher.csv\n",
      "train_simplified/shovel.csv\n",
      "train_simplified/dumbbell.csv\n",
      "train_simplified/rainbow.csv\n",
      "train_simplified/door.csv\n",
      "train_simplified/toothpaste.csv\n",
      "train_simplified/canoe.csv\n",
      "train_simplified/sailboat.csv\n",
      "train_simplified/mouth.csv\n",
      "train_simplified/horse.csv\n",
      "train_simplified/clock.csv\n",
      "train_simplified/snake.csv\n",
      "train_simplified/angel.csv\n",
      "train_simplified/hockey stick.csv\n",
      "train_simplified/airplane.csv\n",
      "train_simplified/tiger.csv\n",
      "train_simplified/spoon.csv\n",
      "train_simplified/flower.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 1/30 [00:07<03:35,  7.44s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 2/30 [00:15<03:29,  7.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 3/30 [00:23<03:26,  7.64s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 4/30 [00:30<03:19,  7.67s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|█▋        | 5/30 [00:38<03:12,  7.69s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|██        | 6/30 [00:46<03:05,  7.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██▎       | 7/30 [00:54<03:01,  7.91s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██▋       | 8/30 [01:02<02:56,  8.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███       | 9/30 [01:11<02:49,  8.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|███▎      | 10/30 [01:19<02:43,  8.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|███▋      | 11/30 [01:27<02:35,  8.16s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 12/30 [01:36<02:31,  8.41s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 13/30 [01:45<02:23,  8.46s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████▋     | 14/30 [01:53<02:14,  8.40s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 15/30 [02:01<02:05,  8.38s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████▎    | 16/30 [02:09<01:56,  8.32s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 17/30 [02:18<01:49,  8.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 18/30 [02:27<01:41,  8.46s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████▎   | 19/30 [02:36<01:34,  8.57s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████▋   | 20/30 [02:44<01:26,  8.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|███████   | 21/30 [02:53<01:18,  8.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████▎  | 22/30 [03:02<01:09,  8.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 23/30 [03:11<01:01,  8.76s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|████████  | 24/30 [03:19<00:52,  8.71s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████▎ | 25/30 [03:28<00:44,  8.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████▋ | 26/30 [03:37<00:35,  8.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████ | 27/30 [03:46<00:26,  8.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|█████████▎| 28/30 [03:55<00:17,  8.95s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████▋| 29/30 [04:04<00:09,  9.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 30/30 [04:14<00:00,  9.10s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#for i,c in enumerate(tqdm(class_paths[0: num_classes])):\n",
    "data_paths = np.random.choice(class_paths, num_classes)\n",
    "print 'Randomly sampled {0} classes.'.format(num_classes)\n",
    "for p in data_paths:\n",
    "    print(p)\n",
    "for i,c in enumerate(tqdm(data_paths)):\n",
    "    train = pd.read_csv(c, usecols=['drawing', 'recognized'], nrows=ims_per_class*5//4)\n",
    "    train = train[train.recognized == True].head(ims_per_class)\n",
    "    imagebag = bag.from_sequence(train.drawing.values).map(draw_it) \n",
    "    trainarray = np.array(imagebag.compute())  # PARALLELIZE\n",
    "    trainarray = np.reshape(trainarray, (ims_per_class, -1))    \n",
    "    labelarray = np.full((train.shape[0], 1), i)\n",
    "    trainarray = np.concatenate((labelarray, trainarray), axis=1)\n",
    "    train_grand.append(trainarray)\n",
    "    \n",
    "train_grand = np.array([train_grand.pop() for i in np.arange(num_classes)]) #less memory than np.concatenate\n",
    "train_grand = train_grand.reshape((-1, (imheight*imwidth+1)))\n",
    "\n",
    "del trainarray\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 30)\n",
      "(54000, 225, 225, 1)\n",
      "(6000, 30)\n",
      "(6000, 225, 225, 1)\n"
     ]
    }
   ],
   "source": [
    "# memory-friendly alternative to train_test_split?\n",
    "valfrac = 0.1\n",
    "cutpt = int(valfrac * train_grand.shape[0])\n",
    "\n",
    "np.random.shuffle(train_grand)\n",
    "y_train, X_train = train_grand[cutpt: , 0], train_grand[cutpt: , 1:]\n",
    "y_val, X_val = train_grand[0:cutpt, 0], train_grand[0:cutpt, 1:] #validation set is recognized==True\n",
    "\n",
    "del train_grand\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "X_train = X_train.reshape(X_train.shape[0], imheight, imwidth, 1)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "X_val = X_val.reshape(X_val.shape[0], imheight, imwidth, 1)\n",
    "\n",
    "print y_train.shape\n",
    "print X_train.shape\n",
    "print y_val.shape\n",
    "print X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 71, 71, 64)        14464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 31, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 512)         6423040   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 512)         262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 30)          15390     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 8,395,806\n",
      "Trainable params: 8,395,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(15, 15), strides=(3,3), padding='valid', activation='relu', input_shape=(imheight, imwidth, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides = (2,2)))\n",
    "model.add(Conv2D(128, kernel_size=(5, 5), padding='valid', activation='relu', strides=(1,1)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "#Layer 3\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu', strides=(1,1)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu', strides=(1,1)))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu', strides=(1,1)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "\n",
    "# Layer 6\n",
    "model.add(Conv2D(512, kernel_size=(7, 7), padding='valid', activation='relu', strides=(1,1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(512, kernel_size=(1, 1), padding='valid', activation='relu', strides=(1,1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(num_classes, kernel_size=(1, 1), padding='valid', activation='relu', strides=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/25\n",
      " 3584/54000 [>.............................] - ETA: 18:06 - loss: nan - acc: 0.0310 - top_3_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-72c4e53cdffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           verbose = 1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    212\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2978\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def top_3_accuracy(x,y): \n",
    "    t3 = top_k_categorical_accuracy(x,y, 3)\n",
    "    return t3\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='auto', min_delta=0.005, cooldown=5, min_lr=0.001)\n",
    "earlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=5) \n",
    "callbacks = [reduceLROnPlat, earlystop]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', top_3_accuracy])\n",
    "\n",
    "model.fit(x=X_train, y=y_train,\n",
    "          batch_size = 256,\n",
    "          epochs = 25,\n",
    "          validation_data = (X_val, y_val),\n",
    "          callbacks = callbacks,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
